{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGbhaBP4fhYaSfWRF3cxM8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keerthipreddy/ML/blob/main/Untitled36.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "E8Gi_zpR5nLb"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iris = pd.read_csv(\"/content/Iris (2).csv\") #Load Data\n",
        "iris.drop('Id',inplace=True,axis=1) #Drop Id column"
      ],
      "metadata": {
        "id": "KNXE8QdK5tyM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.head().style.background_gradient(cmap =sns.light_palette(\"seagreen\", as_cmap=True)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IUabOMwR5t0r",
        "outputId": "88121487-3c95-4fa8-ec46-7c746952caf2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7930c32b6470>"
            ],
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_33612_row0_col0, #T_33612_row3_col2, #T_33612_row4_col1 {\n",
              "  background-color: #2e8b57;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_33612_row0_col1 {\n",
              "  background-color: #4d9c70;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_33612_row0_col2, #T_33612_row1_col2, #T_33612_row4_col2 {\n",
              "  background-color: #8dbfa2;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_33612_row0_col3, #T_33612_row1_col1, #T_33612_row1_col3, #T_33612_row2_col2, #T_33612_row2_col3, #T_33612_row3_col0, #T_33612_row3_col3, #T_33612_row4_col3 {\n",
              "  background-color: #ebf3ed;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_33612_row1_col0 {\n",
              "  background-color: #7ab493;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "#T_33612_row2_col0 {\n",
              "  background-color: #c5decf;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_33612_row2_col1 {\n",
              "  background-color: #acd0bb;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_33612_row3_col1 {\n",
              "  background-color: #cce2d4;\n",
              "  color: #000000;\n",
              "}\n",
              "#T_33612_row4_col0 {\n",
              "  background-color: #54a075;\n",
              "  color: #f1f1f1;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_33612\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_33612_level0_col0\" class=\"col_heading level0 col0\" >SepalLengthCm</th>\n",
              "      <th id=\"T_33612_level0_col1\" class=\"col_heading level0 col1\" >SepalWidthCm</th>\n",
              "      <th id=\"T_33612_level0_col2\" class=\"col_heading level0 col2\" >PetalLengthCm</th>\n",
              "      <th id=\"T_33612_level0_col3\" class=\"col_heading level0 col3\" >PetalWidthCm</th>\n",
              "      <th id=\"T_33612_level0_col4\" class=\"col_heading level0 col4\" >Species</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_33612_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_33612_row0_col0\" class=\"data row0 col0\" >5.100000</td>\n",
              "      <td id=\"T_33612_row0_col1\" class=\"data row0 col1\" >3.500000</td>\n",
              "      <td id=\"T_33612_row0_col2\" class=\"data row0 col2\" >1.400000</td>\n",
              "      <td id=\"T_33612_row0_col3\" class=\"data row0 col3\" >0.200000</td>\n",
              "      <td id=\"T_33612_row0_col4\" class=\"data row0 col4\" >Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_33612_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_33612_row1_col0\" class=\"data row1 col0\" >4.900000</td>\n",
              "      <td id=\"T_33612_row1_col1\" class=\"data row1 col1\" >3.000000</td>\n",
              "      <td id=\"T_33612_row1_col2\" class=\"data row1 col2\" >1.400000</td>\n",
              "      <td id=\"T_33612_row1_col3\" class=\"data row1 col3\" >0.200000</td>\n",
              "      <td id=\"T_33612_row1_col4\" class=\"data row1 col4\" >Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_33612_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_33612_row2_col0\" class=\"data row2 col0\" >4.700000</td>\n",
              "      <td id=\"T_33612_row2_col1\" class=\"data row2 col1\" >3.200000</td>\n",
              "      <td id=\"T_33612_row2_col2\" class=\"data row2 col2\" >1.300000</td>\n",
              "      <td id=\"T_33612_row2_col3\" class=\"data row2 col3\" >0.200000</td>\n",
              "      <td id=\"T_33612_row2_col4\" class=\"data row2 col4\" >Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_33612_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_33612_row3_col0\" class=\"data row3 col0\" >4.600000</td>\n",
              "      <td id=\"T_33612_row3_col1\" class=\"data row3 col1\" >3.100000</td>\n",
              "      <td id=\"T_33612_row3_col2\" class=\"data row3 col2\" >1.500000</td>\n",
              "      <td id=\"T_33612_row3_col3\" class=\"data row3 col3\" >0.200000</td>\n",
              "      <td id=\"T_33612_row3_col4\" class=\"data row3 col4\" >Iris-setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_33612_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_33612_row4_col0\" class=\"data row4 col0\" >5.000000</td>\n",
              "      <td id=\"T_33612_row4_col1\" class=\"data row4 col1\" >3.600000</td>\n",
              "      <td id=\"T_33612_row4_col2\" class=\"data row4 col2\" >1.400000</td>\n",
              "      <td id=\"T_33612_row4_col3\" class=\"data row4 col3\" >0.200000</td>\n",
              "      <td id=\"T_33612_row4_col4\" class=\"data row4 col4\" >Iris-setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_df = iris.iloc[:,:-1] #Set our training dataframe\n",
        "\n",
        "y_df = iris.iloc[:,-1] # Set our training labels dataframe"
      ],
      "metadata": {
        "id": "t4OeYkpy5t3k"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris['Species'] = iris['Species'].astype(\"category\")\n",
        "codes = iris['Species'].cat.codes\n",
        ""
      ],
      "metadata": {
        "id": "TK8OOJ3v5t58"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, random_state=42, test_size=0.2):\n",
        "    \"\"\"\n",
        "    Splits the data into training and testing sets.\n",
        "\n",
        "    Parameters:\n",
        "        X (numpy.ndarray): Features array of shape (n_samples, n_features).\n",
        "        y (numpy.ndarray): Target array of shape (n_samples,).\n",
        "        random_state (int): Seed for the random number generator. Default is 42.\n",
        "        test_size (float): Proportion of samples to include in the test set. Default is 0.2.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[numpy.ndarray]: A tuple containing X_train, X_test, y_train, y_test.\n",
        "    \"\"\"\n",
        "    # Get number of samples\n",
        "    n_samples = X.shape[0]\n",
        "\n",
        "    # Set the seed for the random number generator\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Shuffle the indices\n",
        "    shuffled_indices = np.random.permutation(np.arange(n_samples))\n",
        "\n",
        "    # Determine the size of the test set\n",
        "    test_size = int(n_samples * test_size)\n",
        "\n",
        "    # Split the indices into test and train\n",
        "    test_indices = shuffled_indices[:test_size]\n",
        "    train_indices = shuffled_indices[test_size:]\n",
        "\n",
        "    # Split the features and target arrays into test and train\n",
        "    X_train, X_test = X[train_indices], X[test_indices]\n",
        "    y_train, y_test = y[train_indices], y[test_indices]\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n"
      ],
      "metadata": {
        "id": "ciyiWkjJ5t8E"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, -1].values.reshape(-1,1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=41)"
      ],
      "metadata": {
        "id": "6bfyXVen5t-k"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "m = DecisionTreeClassifier()"
      ],
      "metadata": {
        "id": "WTPAOVx55uBM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomForest:\n",
        "    \"\"\"\n",
        "    A random forest classifier.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_trees : int, default=7\n",
        "        The number of trees in the random forest.\n",
        "    max_depth : int, default=7\n",
        "        The maximum depth of each decision tree in the random forest.\n",
        "    min_samples : int, default=2\n",
        "        The minimum number of samples required to split an internal node\n",
        "        of each decision tree in the random forest.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    n_trees : int\n",
        "        The number of trees in the random forest.\n",
        "    max_depth : int\n",
        "        The maximum depth of each decision tree in the random forest.\n",
        "    min_samples : int\n",
        "        The minimum number of samples required to split an internal node\n",
        "        of each decision tree in the random forest.\n",
        "    trees : list of DecisionTreeClassifier\n",
        "        The decision trees in the random forest.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_trees=7, max_depth=7, min_samples=2):\n",
        "        \"\"\"\n",
        "        Initialize the random forest classifier.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_trees : int, default=7\n",
        "            The number of trees in the random forest.\n",
        "        max_depth : int, default=7\n",
        "            The maximum depth of each decision tree in the random forest.\n",
        "        min_samples : int, default=2\n",
        "            The minimum number of samples required to split an internal node\n",
        "            of each decision tree in the random forest.\n",
        "        \"\"\"\n",
        "        self.n_trees = n_trees\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples = min_samples\n",
        "        self.trees = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        \"\"\"\n",
        "        Build a random forest classifier from the training set (X, y).\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The training input samples.\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The target values.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        self : object\n",
        "            Returns self.\n",
        "        \"\"\"\n",
        "        # Create an empty list to store the trees.\n",
        "        self.trees = []\n",
        "        # Concatenate X and y into a single dataset.\n",
        "        dataset = np.concatenate((X, y.reshape(-1, 1)), axis=1)\n",
        "        # Loop over the number of trees.\n",
        "        for _ in range(self.n_trees):\n",
        "            # Create a decision tree instance.\n",
        "            tree = DecisionTreeClassifier(max_depth=self.max_depth, min_samples_split=self.min_samples)\n",
        "            # Sample from the dataset with replacement (bootstrapping).\n",
        "            dataset_sample = self.bootstrap_samples(dataset)\n",
        "            # Get the X and y samples from the dataset sample.\n",
        "            X_sample, y_sample = dataset_sample[:, :-1], dataset_sample[:, -1]\n",
        "            # Fit the tree to the X and y samples.\n",
        "            tree.fit(X_sample, y_sample)\n",
        "            # Store the tree in the list of trees.\n",
        "            self.trees.append(tree)\n",
        "        return self\n",
        "\n",
        "    def bootstrap_samples(self, dataset):\n",
        "        \"\"\"\n",
        "        Bootstrap the dataset by sampling from it with replacement.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        dataset : array-like of shape (n_samples, n_features + 1)\n",
        "            The dataset to bootstrap.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        dataset_sample : array-like of shape (n_samples, n_features + 1)\n",
        "            The bootstrapped dataset sample.\n",
        "        \"\"\"\n",
        "        # Get the number of samples in the dataset.\n",
        "        n_samples = dataset.shape[0]\n",
        "        # Generate random indices to index into the dataset with replacement.\n",
        "        np.random.seed(1)\n",
        "        indices = np.random.choice(n_samples, n_samples, replace=True)\n",
        "        # Return the bootstrapped dataset sample using the generated indices.\n",
        "        dataset_sample = dataset[indices]\n",
        "        return dataset_sample\n",
        "\n",
        "    def most_common_label(self, y):\n",
        "        \"\"\"\n",
        "        Return the most common label in an array of labels.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        y : array-like of shape (n_samples,)\n",
        "            The array of labels.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        most_occuring_value : int or float\n",
        "            The most common label in the array.\n",
        "        \"\"\"\n",
        "        y = list(y)\n",
        "        # get the highest present class in the array\n",
        "        most_occuring_value = max(y, key=y.count)\n",
        "        return most_occuring_value\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict class for X.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            The input samples.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        majority_predictions : array-like of shape (n_samples,)\n",
        "            The predicted classes.\n",
        "        \"\"\"\n",
        "        #get prediction from each tree in the tree list on the test data\n",
        "        predictions = np.array([tree.predict(X) for tree in self.trees])\n",
        "        # get prediction for the same sample from all trees for each sample in the test data\n",
        "        preds = np.swapaxes(predictions, 0, 1)\n",
        "        #get the most voted value by the trees and store it in the final predictions array\n",
        "        majority_predictions = np.array([self.most_common_label(pred) for pred in preds])\n",
        "        return majority_predictions"
      ],
      "metadata": {
        "id": "BU6WDsd_78h-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Computes the accuracy of a classification model.\n",
        "\n",
        "    Parameters:\n",
        "    y_true (numpy array): A numpy array of true labels for each data point.\n",
        "    y_pred (numpy array): A numpy array of predicted labels for each data point.\n",
        "\n",
        "    Returns:\n",
        "    float: The accuracy of the model, expressed as a percentage.\n",
        "    \"\"\"\n",
        "    y_true = y_true.flatten()\n",
        "    total_samples = len(y_true)\n",
        "    correct_predictions = np.sum(y_true == y_pred)\n",
        "    return (correct_predictions / total_samples)"
      ],
      "metadata": {
        "id": "40gjoOuD78lV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVK37hkb78nl",
        "outputId": "db03dc0a-068e-41d4-f951-9b065e4b29ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train.ravel())\n",
        "y_test_encoded = label_encoder.transform(y_test.ravel())\n",
        "model = RandomForest(10, 10, 2)\n",
        "model.fit(X_train, y_train_encoded)\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "accuracy(y_test_encoded, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwlREhNb78p0",
        "outputId": "c36c9a12-c63b-41e6-aae4-35c9359e38f2"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Create and train the decision tree model\n",
        "dt = DecisionTreeClassifier()\n",
        "dt.fit(X_train, y_train_encoded)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = dt.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy(y_test_encoded, predictions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLd0_SX58FXN",
        "outputId": "06b45238-563f-4a0c-dd56-c4bc7947d8ab"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}